{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "from eggd800.signal import demux, butter_lowpass_filter  # for demuxing and filtering\n",
    "import scipy.io.wavfile  # for reading in audiofiles\n",
    "\n",
    "import parselmouth as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes that the raw WAV files are kept in a subfolder named 'raw', and will output calibrated files in a subfolder called 'calibrated'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromdir = os.path.abspath('./raw')\n",
    "todir = os.path.abspath('./calibrated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['luciana_20190616.wav', 'marquinho_20190616.wav', 'jako_20190616.wav']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in os.listdir(fromdir) if f[-4:]=='.wav']  # get a list of the raw audio files\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set values for smoothing and calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are default smoothing values\n",
    "cutoff = 50\n",
    "order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a dictionary containing spans of time in the audiofile where the mask is not on, in order\n",
    "# to determine the best intercepts/zeroes for each recording. Where the span is greater than 50ms, it \n",
    "# has been arbitrarily limited to 50ms (to reduce processing time)\n",
    "zerospans = {\n",
    "    'luciana': [150,200],\n",
    "    'jako': [250, 300],\n",
    "    'marquinho': [118, 140]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are mask sizes of the subjects\n",
    "mask = {\n",
    "    'luciana': 'small',\n",
    "    'jako': 'small',\n",
    "    'marquinho': 'small'\n",
    "}\n",
    "\n",
    "# These are the previously determined calibration slopes and intercepts from previous Panara calibration\n",
    "big_calib ={\n",
    "    'nas_slope': 3900,\n",
    "    'nas_interc': 274,\n",
    "    'ora_slope': 323,\n",
    "    'ora_interc':763\n",
    "}\n",
    "\n",
    "small_calib ={\n",
    "    'nas_slope': 7456,\n",
    "    'nas_interc': 206,\n",
    "    'ora_slope': 801,\n",
    "    'ora_interc': 755\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell loops through each wav file in the raw data folder and does the following:\n",
    "1. separates the 2 channels into 4, performs smoothing on each channel, and then recombines them into a 3-channel wav file, with audio, nasal airflow, and oral airflow, saved as tmp.wav in the current directory\n",
    "1. reads tmp.wav as a Parselmouth Sound object\n",
    "1. determines the average value during the zerospans -- periods of time when the recording should read zero for both oral and nasal airflow\n",
    "1. calibrates the channels based on the slopes from previous calibration and intercepts determined in the previous step\n",
    "1. recombines the channels into a wav file with the original name plus the suffix `_calibrated` in the target directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luciana\t457.42245590487164\t761.023029610494\n",
      "marquinho\t453.7605006361297\t761.1289517435016\n",
      "jako\t493.26027835906984\t764.5326677579752\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    \n",
    "    destfile = os.path.join(todir,f[0:-4]+'_calibrated'+'.wav') # name the destination file\n",
    "    \n",
    "    (au, lx, p1, p2) = demux(scipy.io.wavfile.read(os.path.join(fromdir,f))[1]) # separate channels\n",
    "    subject = f.split('_')[0] # get subject -- needed for calibration\n",
    "\n",
    "    # get the sampling frequency of the audiofile, to reconstruct time\n",
    "    # this has to be halved because there actually four channels, not two\n",
    "    rate = scipy.io.wavfile.read(os.path.join(fromdir,f))[0]/2\n",
    "\n",
    "    af_n = butter_lowpass_filter(p1, cutoff, rate, order)  # nasal airflow on p1\n",
    "    af_o = butter_lowpass_filter(p2, cutoff, rate, order)  # oral airflow on p2\n",
    "\n",
    "    # recombine channels and write to a temporary wav file\n",
    "    ch_au = np.asarray(au/max(abs(au)), dtype=np.float32)\n",
    "    ch_n = np.asarray(af_n, dtype=np.float32)\n",
    "    ch_o = np.asarray(af_o, dtype=np.float32)\n",
    "    chs = np.vstack((ch_au, ch_n, ch_o)).T\n",
    "    scipy.io.wavfile.write('./tmp.wav', rate=int(rate), data=chs)\n",
    "\n",
    "    # read tmp.wav and get the average values of nasal and oral airflow channels when it should be zero\n",
    "    sound = ps.read('./tmp.wav')\n",
    "    zerosound = sound.extract_part(zerospans[subject][0], zerospans[subject][1])\n",
    "    nas_interc = np.mean(zerosound.as_array()[1])\n",
    "    ora_interc = np.mean(zerosound.as_array()[2])\n",
    "    print('\\t'.join([subject,str(nas_interc),str(ora_interc)])) # print the zeroes, for fun\n",
    "    \n",
    "    # calibrate!\n",
    "    if mask[subject] == 'small':\n",
    "        af_o = (af_o-ora_interc)/small_calib['ora_slope']\n",
    "        af_n = (af_n-nas_interc)/small_calib['nas_slope']\n",
    "    else:\n",
    "        af_o = (af_o-ora_interc)/big_calib['ora_slope']\n",
    "        af_n = (af_n-nas_interc)/big_calib['nas_slope']\n",
    "\n",
    "    # recombine channels and write to final calibrated file\n",
    "    ch_n = np.asarray(af_n, dtype=np.float32)\n",
    "    ch_o = np.asarray(af_o, dtype=np.float32)\n",
    "    chs = np.vstack((ch_au, ch_n, ch_o)).T\n",
    "    scipy.io.wavfile.write(destfile, rate=int(rate), data=chs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
